import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.chains.retrieval_qa.base import RetrievalQA
import json

# üîë Set your OpenAI API key
from dotenv import load_dotenv
load_dotenv()

# 1Ô∏è‚É£ Load PDF
loader = PyPDFLoader("cv.pdf")
documents = loader.load()

# 2Ô∏è‚É£ Split into chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=10
)
docs = text_splitter.split_documents(documents)

# 3Ô∏è‚É£ Create embeddings
embeddings = OpenAIEmbeddings()

# 4Ô∏è‚É£ Store in vector DB (FAISS)
vectorstore = Chroma.from_documents(
        documents=docs,
        embedding=embeddings
    )

# 5Ô∏è‚É£ Create retriever
retriever = vectorstore.as_retriever()

# 6Ô∏è‚É£ LLM
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# 7Ô∏è‚É£ RAG Chain
qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True
)

# 8Ô∏è‚É£ Ask Question
query = "What is this document about?"
result = qa({"query": query})

print("Answer:\n", result["result"])
